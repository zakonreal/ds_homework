{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakonreal/ds_homework/blob/main/template_seq2seq_CW_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "in0PyicHhZDG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "73ieMA485Tme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465dc9ae-793e-4a6c-f47f-09e06cd731a5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fn = 'drive/My Drive/dataset_text.txt'\n"
      ],
      "metadata": {
        "id": "Os4tVkvmkTIp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "class DatasetSeq2Seq(Dataset):\n",
        "    def __init__(self, file_name, train_lang='en', bos: str = '~', eos: str = '#'):\n",
        "\n",
        "        with open(file_name, 'r') as f:\n",
        "            train = f.readlines()\n",
        "\n",
        "        # init vocabs with spetial tokens\n",
        "        self.input_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n",
        "        self.output_sequnces_vocab = {'pad': 0, bos: 1, eos: 2}\n",
        "\n",
        "        self.input_sequnces = []\n",
        "        self.output_sequnces = []\n",
        "\n",
        "        n_input = 3\n",
        "        n_output = 3\n",
        "        for line in train:\n",
        "            split_line = line.split('\\t')\n",
        "\n",
        "            sequence = [self.input_sequnces_vocab[bos]]\n",
        "\n",
        "            for char in split_line[0].strip():\n",
        "                if self.input_sequnces_vocab.get(char) is None:\n",
        "                    self.input_sequnces_vocab[char] = n_input\n",
        "                    n_input += 1\n",
        "                sequence.append(self.input_sequnces_vocab[char])\n",
        "            sequence.append(self.input_sequnces_vocab[eos])\n",
        "\n",
        "            target = [self.output_sequnces_vocab[bos]]\n",
        "            for char in split_line[2].strip():\n",
        "                if self.output_sequnces_vocab.get(char) is None:\n",
        "                    self.output_sequnces_vocab[char] = n_output\n",
        "                    n_output += 1\n",
        "                target.append(self.output_sequnces_vocab[char])\n",
        "            target.append(self.output_sequnces_vocab[eos])\n",
        "\n",
        "            self.input_sequnces.append(sequence)\n",
        "            self.output_sequnces.append(target)\n",
        "\n",
        "        self.target_decode = [k for k in self.output_sequnces_vocab.keys()]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_sequnces)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.input_sequnces[index],\n",
        "            'target': self.output_sequnces[index],\n",
        "        }\n",
        "\n",
        "\n",
        "def collate_fn(input_data):\n",
        "    data = []\n",
        "    targets = []\n",
        "\n",
        "    for item in input_data:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        targets.append(torch.as_tensor(item['target']))\n",
        "\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "    data_mask = data > 0\n",
        "    targets_mask = targets > 0\n",
        "\n",
        "    return {'data': data, \n",
        "            'target': targets, \n",
        "            'data_mask': data_mask, \n",
        "            'targets_mask': targets_mask,\n",
        "            }"
      ],
      "metadata": {
        "id": "SI8UCZuy7hTK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetSeq2Seq(fn)"
      ],
      "metadata": {
        "id": "dhJuBtoz7f43"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zXXXYP37gFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#    test = '17 ноября 2022 г.'\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.emb(x)\n",
        "        _, context = self.rnn(emb)\n",
        "\n",
        "        return context\n",
        "# 1 vector \n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim, eos_id, n_iter = 20):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(hidden_dim, vocab_len)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.eos_id = eos_id\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def forward(self, context, target_sequence):\n",
        "        if self.training:\n",
        "            # traget sequence начиналась с bos, например ~2022-11-17\n",
        "            emb = self.emb(target_sequence)\n",
        "            dec_context, _ = self.rnn(emb, context)\n",
        "            pred = self.clf(self.do(dec_context))\n",
        "\n",
        "            return pred\n",
        "        else:\n",
        "            predicts = []\n",
        "            # в инференсе в target sequene будет только bos\n",
        "            predicted_token = target_sequence # [~]\n",
        "            i = 0\n",
        "            while predicted_token.item() != self.eos_id and i < self.n_iter:\n",
        "                emb = self.emb(predicted_token) \n",
        "                context, _ = self.rnn(emb, context) \n",
        "                pred = self.clf(self.do(context))\n",
        "                predicted_token = torch.argmax(pred, dim=-1)\n",
        "                predicts.append(predicted_token)\n",
        "                i += 1\n",
        "            \n",
        "            return torch.cat(predicts, dim=-1)\n",
        "\n",
        "   # 2022-11-17#     "
      ],
      "metadata": {
        "id": "uPJauY4hAqJ6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateNormalizer(nn.Module):\n",
        "    def __init__(self, input_vocab_len, target_vocab_len, \n",
        "                 emb__dim, hidden_dim, eos_id):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(input_vocab_len, emb_dim, hidden_dim)\n",
        "        self.decoder = Decoder(target_vocab_len, emb_dim, hidden_dim, eos_id)\n",
        "\n",
        "    def forward(self, x, target_sequence):\n",
        "        context = self.encoder(x)\n",
        "        pred = self.decoder(context, target_sequence)\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "KTz2txO4LTZ3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WBFZc1qY6HsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "input_vocab_size = len(dataset.input_sequnces_vocab)\n",
        "target_vocab_size = len(dataset.output_sequnces_vocab)\n",
        "eos_id = dataset.output_sequnces_vocab['#']\n",
        "#TODO try to use other model parameters\n",
        "emb_dim = 128\n",
        "hidden = 256\n",
        "n_epochs = 20\n",
        "batch_size = 64\n",
        "cuda_device = 0\n",
        "batch_size = 100\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "K_PACmDaH8Z7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DateNormalizer(input_vocab_size, target_vocab_size, emb_dim, hidden, eos_id).to(device)\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "a4gX5zVDIZdu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVX0P0otIk4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9bMsBeqV8GCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        target = batch['target'].to(device)\n",
        "        predicts = model(batch['data'].to(device), target[:, :-1])\n",
        "        loss = loss_func(predicts.reshape(-1, target_vocab_size), \n",
        "                         target[:, 1:].reshape(-1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    test = '17 ноября 2016 г.'\n",
        "    test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n",
        "    test_encoded = test_encoded.to(device)\n",
        "    bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_pred = model(test_encoded, bos_input)\n",
        "        model.train()\n",
        "    decode = list(dataset.output_sequnces_vocab.keys())\n",
        "    out_str = ''\n",
        "    for i in test_pred.squeeze().cpu().detach().tolist():\n",
        "        out_str += decode[i]\n",
        "    print(out_str)\n",
        "\n",
        "    torch.save(model.state_dict(), f'./seq2seq_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2f3MATJ8GKb",
        "outputId": "9ccd02e3-ef4c-402d-a7a8-c029c49e44de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.659621477127075\n",
            "1981-06-05#\n",
            "epoch: 1, step: 0, loss: 0.9378378987312317\n",
            "2001-08-26#\n",
            "epoch: 2, step: 0, loss: 0.8382123708724976\n",
            "2016-07-23#\n",
            "epoch: 3, step: 0, loss: 0.6852652430534363\n",
            "2016-01-11#\n",
            "epoch: 4, step: 0, loss: 0.6052967309951782\n",
            "2016-08-23#\n",
            "epoch: 5, step: 0, loss: 0.566204309463501\n",
            "2016-08-18#\n",
            "epoch: 6, step: 0, loss: 0.5309896469116211\n",
            "2016-07-07#\n",
            "epoch: 7, step: 0, loss: 0.4897933602333069\n",
            "2016-10-06#\n",
            "epoch: 8, step: 0, loss: 0.43248680233955383\n",
            "2016-11-27#\n",
            "epoch: 9, step: 0, loss: 0.36058706045150757\n",
            "2016-11-15#\n",
            "epoch: 10, step: 0, loss: 0.3123369812965393\n",
            "2016-11-17#\n",
            "epoch: 11, step: 0, loss: 0.25164487957954407\n",
            "2016-11-17#\n",
            "epoch: 12, step: 0, loss: 0.17011931538581848\n",
            "2016-11-17#\n",
            "epoch: 13, step: 0, loss: 0.1199006661772728\n",
            "2016-11-15#\n",
            "epoch: 14, step: 0, loss: 0.09101741760969162\n",
            "2016-11-25#\n",
            "epoch: 15, step: 0, loss: 0.051678817719221115\n",
            "2016-11-25#\n",
            "epoch: 16, step: 0, loss: 0.03478477522730827\n",
            "2016-11-17#\n",
            "epoch: 17, step: 0, loss: 0.02712005004286766\n",
            "2016-11-17#\n",
            "epoch: 18, step: 0, loss: 0.016249410808086395\n",
            "2016-11-25#\n",
            "epoch: 19, step: 0, loss: 0.014915740117430687\n",
            "2016-11-17#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = '21 11 2019'\n",
        "test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n",
        "test_encoded = test_encoded.to(device)\n",
        "bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_pred = model(test_encoded, bos_input)\n",
        "    model.train()\n",
        "decode = list(dataset.output_sequnces_vocab.keys())\n",
        "out_str = ''\n",
        "for i in test_pred.squeeze().cpu().detach().tolist():\n",
        "    out_str += decode[i]\n",
        "print(out_str)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX_HfQr6Zzra",
        "outputId": "98d8f685-490d-4b41-cc4f-6d160763837f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2016-02-10#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "soes4kIU8FDq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9976594c-63e9-4f11-b206-b2fdb8a90b35"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    ''' Scaled Dot-Product Attention '''\n",
        "\n",
        "    def __init__(self, temperature=1, attn_dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.dropout = nn.Dropout(attn_dropout)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "\n",
        "        attn = torch.bmm(q, # B x T1 x V\n",
        "                         k.transpose(1, 2), # B x T2 x V -> B x V x T2\n",
        "                         ) # B x T1 x T2\n",
        "        attn = attn / self.temperature\n",
        "\n",
        "        if mask is not None:\n",
        "            # print(attn.size(), mask.size())\n",
        "            attn = attn.masked_fill(~mask, -np.inf)\n",
        "\n",
        "        attn = self.softmax(attn)\n",
        "\n",
        "        if mask is not None:\n",
        "            attn = attn.masked_fill(~mask, 0.)\n",
        "\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.bmm(attn, v) # B x T1 x T2 @ B x T1 x V\n",
        "\n",
        "        return output, attn"
      ],
      "metadata": {
        "id": "9PbgCjN48FRe"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class EncoderAttn(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.emb(x)\n",
        "        full_context, context = self.rnn(emb)\n",
        "\n",
        "        return context, full_context\n",
        "# 1 vector \n",
        "\n",
        "\n",
        "class DecoderAttn(nn.Module):\n",
        "    def __init__(self, vocab_len, emb_dim, hidden_dim, eos_id, n_iter = 20):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_len, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "        self.clf = nn.Linear(2 * hidden_dim , vocab_len)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.eos_id = eos_id\n",
        "        self.n_iter = n_iter\n",
        "        self.attn = ScaledDotProductAttention()\n",
        "\n",
        "    def forward(self, context, target_sequence, enc_context):\n",
        "        if self.training:\n",
        "            # traget sequence начиналась с bos, например ~2022-11-17\n",
        "            emb = self.emb(target_sequence)\n",
        "            dec_context, _ = self.rnn(emb, context)\n",
        "            attn, attn_mtx = self.attn(dec_context, enc_context, enc_context)\n",
        "            pred = self.clf(self.do(torch.cat((dec_context, attn), dim=-1)))\n",
        "\n",
        "            return pred\n",
        "        else:\n",
        "            predicts = []\n",
        "            # в инференсе в target sequene будет только bos\n",
        "            predicted_token = target_sequence # [~]\n",
        "            i = 0\n",
        "            while predicted_token.item() != self.eos_id and i < self.n_iter:\n",
        "                emb = self.emb(predicted_token) \n",
        "                context, _ = self.rnn(emb, context)\n",
        "                attn, attn_mtx = self.attn(context, enc_context, enc_context) \n",
        "                pred = self.clf(self.do(torch.cat((context, attn), dim=-1)))\n",
        "                predicted_token = torch.argmax(pred, dim=-1)\n",
        "                predicts.append(predicted_token)\n",
        "                i += 1\n",
        "            \n",
        "            return torch.cat(predicts, dim=-1)\n"
      ],
      "metadata": {
        "id": "74gggSX58Fe9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DateNormalizerAttn(nn.Module):\n",
        "    def __init__(self, input_vocab_len, target_vocab_len, \n",
        "                 emb__dim, hidden_dim, eos_id):\n",
        "        super().__init__()\n",
        "        self.encoder = EncoderAttn(input_vocab_len, emb_dim, hidden_dim)\n",
        "        self.decoder = DecoderAttn(target_vocab_len, emb_dim, hidden_dim, eos_id)\n",
        "\n",
        "    def forward(self, x, target_sequence, mask=None):\n",
        "        context, all_hid = self.encoder(x)\n",
        "        pred = self.decoder(context, target_sequence, all_hid)\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "aSpU1B3rn55K"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DateNormalizerAttn(input_vocab_size, target_vocab_size, emb_dim, hidden, eos_id).to(device)\n",
        "model.train()\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "cSCaZvfpn6FO"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "        target = batch['target'].to(device)\n",
        "        predicts = model(batch['data'].to(device), target[:, :-1])#, batch['data_mask'].to(device).unsqueeze(-1))\n",
        "        loss = loss_func(predicts.reshape(-1, target_vocab_size), \n",
        "                         target[:, 1:].reshape(-1))\n",
        "        \n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "    test = '17 ноября 1117 г.'\n",
        "    test_encoded = torch.tensor([[dataset.input_sequnces_vocab[c] for c in test]])\n",
        "    test_encoded = test_encoded.to(device)\n",
        "    bos_input = torch.tensor([[dataset.output_sequnces_vocab['~']]]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        test_pred = model(test_encoded, bos_input)\n",
        "        model.train()\n",
        "    decode = list(dataset.output_sequnces_vocab.keys())\n",
        "    out_str = ''\n",
        "    for i in test_pred.squeeze().cpu().detach().tolist():\n",
        "        out_str += decode[i]\n",
        "    print(out_str)\n",
        "\n",
        "    torch.save(model.state_dict(), f'./seq2seq_chkpt_{epoch}.pth')"
      ],
      "metadata": {
        "id": "dHqoAJO_n6Qv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a0b1dd3-3430-4d96-aa15-50880c756de6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.6311402320861816\n",
            "19-11-11#\n",
            "epoch: 1, step: 0, loss: 0.6921329498291016\n",
            "197-11-17#\n",
            "epoch: 2, step: 0, loss: 0.33260130882263184\n",
            "179-11-17#\n",
            "epoch: 3, step: 0, loss: 0.25539249181747437\n",
            "197-11-17#\n",
            "epoch: 4, step: 0, loss: 0.20052093267440796\n",
            "197-11-17#\n",
            "epoch: 5, step: 0, loss: 0.15609432756900787\n",
            "197-11-17#\n",
            "epoch: 6, step: 0, loss: 0.10102508217096329\n",
            "197-11-17#\n",
            "epoch: 7, step: 0, loss: 0.11237550526857376\n",
            "177-11-17#\n",
            "epoch: 8, step: 0, loss: 0.11031936854124069\n",
            "197-11-17#\n",
            "epoch: 9, step: 0, loss: 0.10493025928735733\n",
            "2017-11-17#\n",
            "epoch: 10, step: 0, loss: 0.09298008680343628\n",
            "197-11-17#\n",
            "epoch: 11, step: 0, loss: 0.08472450077533722\n",
            "197-11-17#\n",
            "epoch: 12, step: 0, loss: 0.08383988589048386\n",
            "1977-11-17#\n",
            "epoch: 13, step: 0, loss: 0.06451080739498138\n",
            "197-11-17#\n",
            "epoch: 14, step: 0, loss: 0.0718255266547203\n",
            "177-11-17#\n",
            "epoch: 15, step: 0, loss: 0.07386622577905655\n",
            "1977-11-17#\n",
            "epoch: 16, step: 0, loss: 0.0654057115316391\n",
            "197-11-17#\n",
            "epoch: 17, step: 0, loss: 0.07821540534496307\n",
            "1971-11-17#\n",
            "epoch: 18, step: 0, loss: 0.06666850298643112\n",
            "2017-11-17#\n",
            "epoch: 19, step: 0, loss: 0.05826352909207344\n",
            "1977-11-17#\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5lRJEguzqSJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-57Jq-CW8NmD"
      }
    }
  ]
}