{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakonreal/ds_homework/blob/main/HW_DL_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "in0PyicHhZDG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "73ieMA485Tme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2305b885-28cf-4a27-cfae-d4371906a5c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/My Drive/'\n",
        "train_lang = 'en'"
      ],
      "metadata": {
        "id": "Os4tVkvmkTIp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class DatasetSeq(Dataset):\n",
        "    def __init__(self, data_dir, train_lang='en'):\n",
        "\t#open file\n",
        "        with open(data_dir + train_lang + '.train', 'r') as f:\n",
        "            train = f.read().split('\\n\\n')\n",
        "\n",
        "        # delete extra tag markup\n",
        "        train = [x for x in train if not '_ ' in x]\n",
        "\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n",
        "        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n",
        "        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
        "        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
        "\t    \n",
        "        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n",
        "        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n",
        "        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n",
        "\n",
        "\t    #init encoded sequences lists (processed data)\n",
        "        self.encoded_sequences = []\n",
        "        self.encoded_targets = []\n",
        "        self.encoded_char_sequences = []\n",
        "        # n=1 because first value is padding\n",
        "        n_word = 1\n",
        "        n_target = 1\n",
        "        n_char = 1\n",
        "        for line in train:\n",
        "            sequence = []\n",
        "            target = []\n",
        "            chars = []\n",
        "            for item in line.split('\\n'):\n",
        "                if item != '':\n",
        "                    word, label = item.split(' ')\n",
        "\n",
        "                    if self.word_vocab.get(word) is None:\n",
        "                        self.word_vocab[word] = n_word\n",
        "                        n_word += 1\n",
        "                    if self.target_vocab.get(label) is None:\n",
        "                        self.target_vocab[label] = n_target\n",
        "                        n_target += 1\n",
        "                    for char in word:\n",
        "                        if self.char_vocab.get(char) is None:\n",
        "                            self.char_vocab[char] = n_char\n",
        "                            n_char += 1\n",
        "                    sequence.append(self.word_vocab[word])\n",
        "                    target.append(self.target_vocab[label])\n",
        "                    chars.append([self.char_vocab[char] for char in word])\n",
        "            self.encoded_sequences.append(sequence)\n",
        "            self.encoded_targets.append(target)\n",
        "            self.encoded_char_sequences.append(chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
        "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
        "            'target': self.encoded_targets[index], #  (1)\n",
        "        }"
      ],
      "metadata": {
        "id": "SI8UCZuy7hTK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetSeq(data_dir)"
      ],
      "metadata": {
        "id": "dhJuBtoz7f43"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "# seq1 = [1, 2, 3, 4]\n",
        "# seq2 = [9, 7, 6, 4, 3, 7, 5]\n",
        "# pad seq1 equal seq2\n",
        "# seq1 = [1, 2, 3, 4, 0, 0, 0]\n",
        "# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n",
        "#                     [9, 7, 6, 4, 3, 7, 5]]"
      ],
      "metadata": {
        "id": "0zXXXYP37gFL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    for item in batch:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        target.append(torch.as_tensor(item['target']))\n",
        "    # pad different length sequences\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'data': data, 'target': target}"
      ],
      "metadata": {
        "id": "uPJauY4hAqJ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCellPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn_cell = nn.GRUCell(emb_dim, hidden_dim)\n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x): # B x T\n",
        "        b, t = x.size()\n",
        "        emb = self.word_emb(x) # B x T x Ebm_dim\n",
        "        rnn_out = []\n",
        "        hidden = torch.zeros((b, self.hidden_dim), device=x.device)\n",
        "        for i in range(t):\n",
        "            hidden = self.gru_cell(emb[:, i, :], # emb[:, i, :]: B x Emb_dim\n",
        "                                   hidden) # hidden: B x Hid_dim\n",
        "            rnn_out.append(hidden.unsqueeze(1)) # B x 1 x Hid_dim\n",
        "        rnn_out = torch.cat(rnn_out, dim=1) # B x T x Hid_dim\n",
        "\n",
        "        return self.clf(self.do(rnn_out))\n"
      ],
      "metadata": {
        "id": "KTz2txO4LTZ3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #hyper params\n",
        "# vocab_size = len(dataset.word_vocab) + 1\n",
        "# n_classes = len(dataset.target_vocab) + 1\n",
        "# n_chars = len(dataset.char_vocab) + 1\n",
        "# #TODO try to use other model parameters\n",
        "# emb_dim = 256\n",
        "# hidden = 256\n",
        "# n_epochs = 10\n",
        "# cuda_device = 0\n",
        "# batch_size = 100\n",
        "# device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "K_PACmDaH8Z7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "vocab_size = len(dataset.word_vocab) + 1\n",
        "n_classes = len(dataset.target_vocab) + 1\n",
        "n_chars = len(dataset.char_vocab) + 1\n",
        "#TODO try to use other model parameters\n",
        "emb_dim = 128 # поменял с 256 на 128\n",
        "hidden = 256\n",
        "char_hid = 64\n",
        "char_emb = 32\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "cuda_device = 0\n",
        "batch_size = 100\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "qknU9T_TQkc5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))\n",
        "        "
      ],
      "metadata": {
        "id": "WBFZc1qY6HsC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = RNN_GRU(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model1.train()\n",
        "optim = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "a4gX5zVDIZdu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start1 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model1(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model1.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "GRU_train_time = datetime.datetime.now() - start1\n",
        "GRU_train_loss = loss.item()\n",
        "print(GRU_train_time)\n",
        "print(GRU_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2f3MATJ8GKb",
        "outputId": "6791d658-db27-44c5-ced2-d16b5529e4d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.697464942932129\n",
            "epoch: 0, step: 100, loss: 0.34761226177215576\n",
            "epoch: 0, step: 200, loss: 0.3428894579410553\n",
            "epoch: 1, step: 0, loss: 0.21351249516010284\n",
            "epoch: 1, step: 100, loss: 0.15344545245170593\n",
            "epoch: 1, step: 200, loss: 0.1469312161207199\n",
            "epoch: 2, step: 0, loss: 0.13336654007434845\n",
            "epoch: 2, step: 100, loss: 0.11462906748056412\n",
            "epoch: 2, step: 200, loss: 0.09780871123075485\n",
            "epoch: 3, step: 0, loss: 0.09811171144247055\n",
            "epoch: 3, step: 100, loss: 0.1071963906288147\n",
            "epoch: 3, step: 200, loss: 0.06952792406082153\n",
            "epoch: 4, step: 0, loss: 0.06481955200433731\n",
            "epoch: 4, step: 100, loss: 0.09193825721740723\n",
            "epoch: 4, step: 200, loss: 0.05829273536801338\n",
            "epoch: 5, step: 0, loss: 0.07658292353153229\n",
            "epoch: 5, step: 100, loss: 0.06946925073862076\n",
            "epoch: 5, step: 200, loss: 0.05656103044748306\n",
            "epoch: 6, step: 0, loss: 0.07207252085208893\n",
            "epoch: 6, step: 100, loss: 0.0842195674777031\n",
            "epoch: 6, step: 200, loss: 0.05789846181869507\n",
            "epoch: 7, step: 0, loss: 0.056710630655288696\n",
            "epoch: 7, step: 100, loss: 0.06192448362708092\n",
            "epoch: 7, step: 200, loss: 0.05370796099305153\n",
            "epoch: 8, step: 0, loss: 0.03295019641518593\n",
            "epoch: 8, step: 100, loss: 0.06044112145900726\n",
            "epoch: 8, step: 200, loss: 0.043886102735996246\n",
            "epoch: 9, step: 0, loss: 0.04882444441318512\n",
            "epoch: 9, step: 100, loss: 0.05139648914337158\n",
            "epoch: 9, step: 200, loss: 0.03225962817668915\n",
            "0:00:23.645993\n",
            "0.050930917263031006\n",
            "CPU times: user 22.5 s, sys: 511 ms, total: 23 s\n",
            "Wall time: 23.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start11 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model1.eval()\n",
        "    predict = model1(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    GRU_inference_time = datetime.datetime.now() - start11\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(GRU_inference_time)"
      ],
      "metadata": {
        "id": "9CljFAzIMMEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40fab945-a995-45b9-845f-f456a5cf544c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.001855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "soes4kIU8FDq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RNN_LSTM(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model2.train()\n",
        "optim = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9PbgCjN48FRe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start2 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model2(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model2.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "LSTM_train_time = datetime.datetime.now() - start2\n",
        "LSTM_train_loss = loss.item()\n",
        "print(LSTM_train_time)\n",
        "print(LSTM_train_loss)"
      ],
      "metadata": {
        "id": "74gggSX58Fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75374ff5-8120-4740-e9b1-b6abd7c25abf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.7950456142425537\n",
            "epoch: 0, step: 100, loss: 0.3105144202709198\n",
            "epoch: 0, step: 200, loss: 0.3319418430328369\n",
            "epoch: 1, step: 0, loss: 0.23660987615585327\n",
            "epoch: 1, step: 100, loss: 0.2564547061920166\n",
            "epoch: 1, step: 200, loss: 0.21276871860027313\n",
            "epoch: 2, step: 0, loss: 0.18634840846061707\n",
            "epoch: 2, step: 100, loss: 0.1283894032239914\n",
            "epoch: 2, step: 200, loss: 0.1633543074131012\n",
            "epoch: 3, step: 0, loss: 0.1179714947938919\n",
            "epoch: 3, step: 100, loss: 0.0923578068614006\n",
            "epoch: 3, step: 200, loss: 0.07840301096439362\n",
            "epoch: 4, step: 0, loss: 0.09804749488830566\n",
            "epoch: 4, step: 100, loss: 0.09709502756595612\n",
            "epoch: 4, step: 200, loss: 0.060109544545412064\n",
            "epoch: 5, step: 0, loss: 0.05985260754823685\n",
            "epoch: 5, step: 100, loss: 0.08648263663053513\n",
            "epoch: 5, step: 200, loss: 0.04569769278168678\n",
            "epoch: 6, step: 0, loss: 0.05195637047290802\n",
            "epoch: 6, step: 100, loss: 0.08191590011119843\n",
            "epoch: 6, step: 200, loss: 0.08082637935876846\n",
            "epoch: 7, step: 0, loss: 0.03616645187139511\n",
            "epoch: 7, step: 100, loss: 0.04538877308368683\n",
            "epoch: 7, step: 200, loss: 0.046558063477277756\n",
            "epoch: 8, step: 0, loss: 0.044521789997816086\n",
            "epoch: 8, step: 100, loss: 0.05203494057059288\n",
            "epoch: 8, step: 200, loss: 0.05796433612704277\n",
            "epoch: 9, step: 0, loss: 0.03243572637438774\n",
            "epoch: 9, step: 100, loss: 0.036237817257642746\n",
            "epoch: 9, step: 200, loss: 0.023529618978500366\n",
            "0:00:27.226089\n",
            "0.03653613477945328\n",
            "CPU times: user 24 s, sys: 370 ms, total: 24.3 s\n",
            "Wall time: 27.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start22 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model2.eval()\n",
        "    predict = model2(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    LSTM_inference_time = datetime.datetime.now() - start22\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(LSTM_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JdDhNkOKXh7",
        "outputId": "2b114b39-87e7-45d9-944c-16189cb03d68"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.004043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "mUKmT0hNKXsf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = RNN_LSTM(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model3.train()\n",
        "optim = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "iRr7xCJ-KXvr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start3 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model3(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model3.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "RNN_train_time = datetime.datetime.now() - start3\n",
        "RNN_train_loss = loss.item()\n",
        "print(RNN_train_time)\n",
        "print(RNN_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGo7xQ2xKX22",
        "outputId": "2e4d150e-a36f-413d-f8ae-28d53d40bfdb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.8822274208068848\n",
            "epoch: 0, step: 100, loss: 0.5095211267471313\n",
            "epoch: 0, step: 200, loss: 0.3305400013923645\n",
            "epoch: 1, step: 0, loss: 0.21899423003196716\n",
            "epoch: 1, step: 100, loss: 0.20709535479545593\n",
            "epoch: 1, step: 200, loss: 0.1597582846879959\n",
            "epoch: 2, step: 0, loss: 0.1753382831811905\n",
            "epoch: 2, step: 100, loss: 0.14058679342269897\n",
            "epoch: 2, step: 200, loss: 0.1603178232908249\n",
            "epoch: 3, step: 0, loss: 0.1254953294992447\n",
            "epoch: 3, step: 100, loss: 0.11292046308517456\n",
            "epoch: 3, step: 200, loss: 0.10796342045068741\n",
            "epoch: 4, step: 0, loss: 0.08759182691574097\n",
            "epoch: 4, step: 100, loss: 0.08134536445140839\n",
            "epoch: 4, step: 200, loss: 0.07035689800977707\n",
            "epoch: 5, step: 0, loss: 0.06422707438468933\n",
            "epoch: 5, step: 100, loss: 0.07264790683984756\n",
            "epoch: 5, step: 200, loss: 0.07298268377780914\n",
            "epoch: 6, step: 0, loss: 0.038619861006736755\n",
            "epoch: 6, step: 100, loss: 0.039593227207660675\n",
            "epoch: 6, step: 200, loss: 0.054011519998311996\n",
            "epoch: 7, step: 0, loss: 0.052278146147727966\n",
            "epoch: 7, step: 100, loss: 0.06973864883184433\n",
            "epoch: 7, step: 200, loss: 0.06022263318300247\n",
            "epoch: 8, step: 0, loss: 0.04051268473267555\n",
            "epoch: 8, step: 100, loss: 0.05206732079386711\n",
            "epoch: 8, step: 200, loss: 0.06694240868091583\n",
            "epoch: 9, step: 0, loss: 0.03688303381204605\n",
            "epoch: 9, step: 100, loss: 0.060015060007572174\n",
            "epoch: 9, step: 200, loss: 0.04314855858683586\n",
            "0:00:25.665279\n",
            "0.03157490864396095\n",
            "CPU times: user 24.1 s, sys: 377 ms, total: 24.4 s\n",
            "Wall time: 25.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start33 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model3.eval()\n",
        "    predict = model3(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    RNN_inference_time = datetime.datetime.now() - start33\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(RNN_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6WK7jdJKX6p",
        "outputId": "fa2f262b-0f41-4758-fe7f-ba01b2e2b343"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.001290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn1(input_data):\n",
        "    data = []\n",
        "    chars = []\n",
        "    targets = []\n",
        "    max_len = 0\n",
        "    for item in input_data:\n",
        "        if len(item['data']) > max_len:\n",
        "            max_len = len(item['data'])\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        chars.append(item['char'])\n",
        "        targets.append(torch.as_tensor(item['target']))\n",
        "    chars_seq = [[torch.as_tensor([0]) for _ in range(len(input_data))] for _ in range(max_len)]\n",
        "    for j in range(len(input_data)):\n",
        "        for i in range(max_len):\n",
        "            if len(chars[j]) > i:\n",
        "                chars_seq[i][j] = torch.as_tensor(chars[j][i])\n",
        "    for j in range(max_len):\n",
        "        chars_seq[j] = pad_sequence(chars_seq[j], batch_first=True, padding_value=0)\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "    return {'data': data, 'chars': chars_seq, 'target': targets}"
      ],
      "metadata": {
        "id": "vHNpwzseQPRB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN_GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.char_emb(x) # B x T x Emb_dim\n",
        "        _, out = self.rnn(emb)\n",
        "        # _: B x T x Hidden \n",
        "        # out: 1 x B x Hidden\n",
        "\n",
        "        return out.transpose(0, 1) # B x 1 x Hidden"
      ],
      "metadata": {
        "id": "LKcpp1-eQPXf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_GRU_CH(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n",
        "                 char_vocab, char_emb, char_hidden):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.GRU(emb_dim + char_hidden, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_rnn = CharRNN_GRU(char_vocab, char_emb, char_hidden)\n",
        "\n",
        "    def forward(self, x, chars):\n",
        "        emb = self.word_emb(x)\n",
        "        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n",
        "        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n",
        "        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "8EmOuYOWQPas"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = RNN_GRU_CH(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n",
        "model4.train()\n",
        "optim = torch.optim.Adam(model4.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "mJ64bvufQPeG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start4 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn1,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model4(batch['data'].to(device), batch['chars'])\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model4.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "GRUch_train_time = datetime.datetime.now() - start4\n",
        "GRUch_train_loss = loss.item()\n",
        "print(GRUch_train_time)\n",
        "print(GRUch_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwEopDefQPhX",
        "outputId": "19944090-5463-4426-e267-daf7f3a3f94c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.6814215183258057\n",
            "epoch: 0, step: 100, loss: 0.290275901556015\n",
            "epoch: 0, step: 200, loss: 0.06449785083532333\n",
            "epoch: 1, step: 0, loss: 0.15950611233711243\n",
            "epoch: 1, step: 100, loss: 0.18168722093105316\n",
            "epoch: 1, step: 200, loss: 0.15610025823116302\n",
            "epoch: 2, step: 0, loss: 0.106880784034729\n",
            "epoch: 2, step: 100, loss: 0.09623966366052628\n",
            "epoch: 2, step: 200, loss: 0.07311837375164032\n",
            "epoch: 3, step: 0, loss: 0.05631289258599281\n",
            "epoch: 3, step: 100, loss: 0.09291616082191467\n",
            "epoch: 3, step: 200, loss: 0.07114402204751968\n",
            "epoch: 4, step: 0, loss: 0.06549698859453201\n",
            "epoch: 4, step: 100, loss: 0.06335575878620148\n",
            "epoch: 4, step: 200, loss: 0.07194525003433228\n",
            "epoch: 5, step: 0, loss: 0.051111310720443726\n",
            "epoch: 5, step: 100, loss: 0.05010803043842316\n",
            "epoch: 5, step: 200, loss: 0.06252729892730713\n",
            "epoch: 6, step: 0, loss: 0.05802266299724579\n",
            "epoch: 6, step: 100, loss: 0.0704229399561882\n",
            "epoch: 6, step: 200, loss: 0.05308810994029045\n",
            "epoch: 7, step: 0, loss: 0.053617894649505615\n",
            "epoch: 7, step: 100, loss: 0.048759255558252335\n",
            "epoch: 7, step: 200, loss: 0.041092149913311005\n",
            "epoch: 8, step: 0, loss: 0.04169231653213501\n",
            "epoch: 8, step: 100, loss: 0.03732086345553398\n",
            "epoch: 8, step: 200, loss: 0.04969651997089386\n",
            "epoch: 9, step: 0, loss: 0.03259899839758873\n",
            "epoch: 9, step: 100, loss: 0.0324973464012146\n",
            "epoch: 9, step: 200, loss: 0.02876179665327072\n",
            "0:04:42.053768\n",
            "0.0428178496658802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "#TODO modify inference for model with char input\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n",
        "\n",
        "start44 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model4.eval()\n",
        "    predict = model4(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    GRUch_inference_time = datetime.datetime.now() - start44\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(GRUch_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpQFLHpQPkc",
        "outputId": "5d3f6368-7c93-4c13-b29d-ff9793275514"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADV', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.005445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_LSTM_CH(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n",
        "                 char_vocab, char_emb, char_hidden):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.LSTM(emb_dim + char_hidden, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_rnn = CharRNN_GRU(char_vocab, char_emb, char_hidden)\n",
        "# При создании  класса CharRNN на основе LSTM при тренировке модели аозникант ошибка - attributeerror: tuple object has no attribute transpose. ПОЧЕМУ???\n",
        "    def forward(self, x, chars):\n",
        "        emb = self.word_emb(x)\n",
        "        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n",
        "        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n",
        "        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "UlvXC1RoQRKH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = RNN_LSTM_CH(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n",
        "model5.train()\n",
        "optim = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Oa7azPFWQRNi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start5 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn1,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model5(batch['data'].to(device), batch['chars'])\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model5.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "LSTMch_train_time = datetime.datetime.now() - start5\n",
        "LSTMch_train_loss = loss.item()\n",
        "print(LSTMch_train_time)\n",
        "print(LSTMch_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRWIHLEhQRRQ",
        "outputId": "cad1537d-b9b2-4fef-e350-62aefcfe9cbd"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.7824697494506836\n",
            "epoch: 0, step: 100, loss: 0.34619492292404175\n",
            "epoch: 0, step: 200, loss: 0.19031865894794464\n",
            "epoch: 1, step: 0, loss: 0.19573692977428436\n",
            "epoch: 1, step: 100, loss: 0.20226818323135376\n",
            "epoch: 1, step: 200, loss: 0.1293405294418335\n",
            "epoch: 2, step: 0, loss: 0.10871847718954086\n",
            "epoch: 2, step: 100, loss: 0.12867826223373413\n",
            "epoch: 2, step: 200, loss: 0.07060105353593826\n",
            "epoch: 3, step: 0, loss: 0.05773886665701866\n",
            "epoch: 3, step: 100, loss: 0.08090445399284363\n",
            "epoch: 3, step: 200, loss: 0.06863255798816681\n",
            "epoch: 4, step: 0, loss: 0.08211454004049301\n",
            "epoch: 4, step: 100, loss: 0.06651565432548523\n",
            "epoch: 4, step: 200, loss: 0.06578901410102844\n",
            "epoch: 5, step: 0, loss: 0.053666356950998306\n",
            "epoch: 5, step: 100, loss: 0.0725189670920372\n",
            "epoch: 5, step: 200, loss: 0.05056532844901085\n",
            "epoch: 6, step: 0, loss: 0.052004821598529816\n",
            "epoch: 6, step: 100, loss: 0.059583988040685654\n",
            "epoch: 6, step: 200, loss: 0.058589328080415726\n",
            "epoch: 7, step: 0, loss: 0.04714951291680336\n",
            "epoch: 7, step: 100, loss: 0.04666838422417641\n",
            "epoch: 7, step: 200, loss: 0.04840878024697304\n",
            "epoch: 8, step: 0, loss: 0.03755103424191475\n",
            "epoch: 8, step: 100, loss: 0.04357551410794258\n",
            "epoch: 8, step: 200, loss: 0.030334001407027245\n",
            "epoch: 9, step: 0, loss: 0.03166265785694122\n",
            "epoch: 9, step: 100, loss: 0.016552269458770752\n",
            "epoch: 9, step: 200, loss: 0.041186124086380005\n",
            "0:04:55.345859\n",
            "0.02854471281170845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "#TODO modify inference for model with char input\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n",
        "\n",
        "start55 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model5.eval()\n",
        "    predict = model5(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    LSTMch_inference_time = datetime.datetime.now() - start55\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(LSTMch_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqoQ0HA7QRU1",
        "outputId": "06edea28-451a-42ef-c73d-d5bcb3ad3cc3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.007477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_CH(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n",
        "                 char_vocab, char_emb, char_hidden):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.RNN(emb_dim + char_hidden, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_rnn = CharRNN_GRU(char_vocab, char_emb, char_hidden)\n",
        "\n",
        "    def forward(self, x, chars):\n",
        "        emb = self.word_emb(x)\n",
        "        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n",
        "        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n",
        "        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "2Eb8tW4CUzVQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = RNN_LSTM_CH(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n",
        "model6.train()\n",
        "optim = torch.optim.Adam(model6.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "1SYnM_F6Uzby"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start6 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn1,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model6(batch['data'].to(device), batch['chars'])\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model6.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "RNNch_train_time = datetime.datetime.now() - start6\n",
        "RNNch_train_loss = loss.item()\n",
        "print(RNNch_train_time)\n",
        "print(RNNch_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVyFk-UbUzhH",
        "outputId": "2ef179f7-c4b7-4ef3-8b7e-23165a18c320"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.898219347000122\n",
            "epoch: 0, step: 100, loss: 0.3857155740261078\n",
            "epoch: 0, step: 200, loss: 0.25762447714805603\n",
            "epoch: 1, step: 0, loss: 0.19653448462486267\n",
            "epoch: 1, step: 100, loss: 0.12921006977558136\n",
            "epoch: 1, step: 200, loss: 0.13722196221351624\n",
            "epoch: 2, step: 0, loss: 0.17779207229614258\n",
            "epoch: 2, step: 100, loss: 0.15846620500087738\n",
            "epoch: 2, step: 200, loss: 0.050216637551784515\n",
            "epoch: 3, step: 0, loss: 0.06497295200824738\n",
            "epoch: 3, step: 100, loss: 0.09796146303415298\n",
            "epoch: 3, step: 200, loss: 0.10486404597759247\n",
            "epoch: 4, step: 0, loss: 0.07948961108922958\n",
            "epoch: 4, step: 100, loss: 0.06036562845110893\n",
            "epoch: 4, step: 200, loss: 0.053657907992601395\n",
            "epoch: 5, step: 0, loss: 0.04653461277484894\n",
            "epoch: 5, step: 100, loss: 0.063311867415905\n",
            "epoch: 5, step: 200, loss: 0.06128644943237305\n",
            "epoch: 6, step: 0, loss: 0.06529584527015686\n",
            "epoch: 6, step: 100, loss: 0.05953168496489525\n",
            "epoch: 6, step: 200, loss: 0.06656263768672943\n",
            "epoch: 7, step: 0, loss: 0.046667687594890594\n",
            "epoch: 7, step: 100, loss: 0.07365638017654419\n",
            "epoch: 7, step: 200, loss: 0.054403580725193024\n",
            "epoch: 8, step: 0, loss: 0.026203814893960953\n",
            "epoch: 8, step: 100, loss: 0.053475767374038696\n",
            "epoch: 8, step: 200, loss: 0.056288763880729675\n",
            "epoch: 9, step: 0, loss: 0.04789184406399727\n",
            "epoch: 9, step: 100, loss: 0.049426257610321045\n",
            "epoch: 9, step: 200, loss: 0.0341712161898613\n",
            "0:04:23.559576\n",
            "0.04530510678887367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "#TODO modify inference for model with char input\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n",
        "\n",
        "start66 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model5.eval()\n",
        "    predict = model5(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    RNNch_inference_time = datetime.datetime.now() - start66\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(RNNch_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtTTCB1bUzlX",
        "outputId": "9cd96385-c3f9-40c3-9589-89101d0c5d63"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.007104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(data=[[GRU_train_time, GRU_train_loss, GRU_inference_time],\n",
        "                            [LSTM_train_time, LSTM_train_loss, LSTM_inference_time],\n",
        "                            [RNN_train_time, RNN_train_loss, RNN_inference_time],\n",
        "                            [GRUch_train_time, GRUch_train_loss, GRUch_inference_time],\n",
        "                            [LSTMch_train_time, LSTMch_train_loss, LSTMch_inference_time],\n",
        "                            [RNNch_train_time, RNNch_train_loss, RNNch_inference_time]],\n",
        "                      index = ['GRU','LSTM','RNN', 'GRUch','LSTMch','RNNch'],\n",
        "                      columns = ['Время обучения', 'Loss на обучающей выборке', 'Время инференса'])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "D9y4lzZfL7Ai",
        "outputId": "ff5077f7-cd90-43a2-9c91-ca3139a39737"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Время обучения  Loss на обучающей выборке  \\\n",
              "GRU    0 days 00:00:23.645993                   0.050931   \n",
              "LSTM   0 days 00:00:27.226089                   0.036536   \n",
              "RNN    0 days 00:00:25.665279                   0.031575   \n",
              "GRUch  0 days 00:04:42.053768                   0.042818   \n",
              "LSTMch 0 days 00:04:55.345859                   0.028545   \n",
              "RNNch  0 days 00:04:23.559576                   0.045305   \n",
              "\n",
              "              Время инференса  \n",
              "GRU    0 days 00:00:00.001855  \n",
              "LSTM   0 days 00:00:00.004043  \n",
              "RNN    0 days 00:00:00.001290  \n",
              "GRUch  0 days 00:00:00.005445  \n",
              "LSTMch 0 days 00:00:00.007477  \n",
              "RNNch  0 days 00:00:00.007104  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66c5a3e0-e134-48e1-9246-d8b895a5bc07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Время обучения</th>\n",
              "      <th>Loss на обучающей выборке</th>\n",
              "      <th>Время инференса</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0 days 00:00:23.645993</td>\n",
              "      <td>0.050931</td>\n",
              "      <td>0 days 00:00:00.001855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>0 days 00:00:27.226089</td>\n",
              "      <td>0.036536</td>\n",
              "      <td>0 days 00:00:00.004043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNN</th>\n",
              "      <td>0 days 00:00:25.665279</td>\n",
              "      <td>0.031575</td>\n",
              "      <td>0 days 00:00:00.001290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRUch</th>\n",
              "      <td>0 days 00:04:42.053768</td>\n",
              "      <td>0.042818</td>\n",
              "      <td>0 days 00:00:00.005445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTMch</th>\n",
              "      <td>0 days 00:04:55.345859</td>\n",
              "      <td>0.028545</td>\n",
              "      <td>0 days 00:00:00.007477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNNch</th>\n",
              "      <td>0 days 00:04:23.559576</td>\n",
              "      <td>0.045305</td>\n",
              "      <td>0 days 00:00:00.007104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66c5a3e0-e134-48e1-9246-d8b895a5bc07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-66c5a3e0-e134-48e1-9246-d8b895a5bc07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-66c5a3e0-e134-48e1-9246-d8b895a5bc07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-57Jq-CW8NmD"
      }
    }
  ]
}