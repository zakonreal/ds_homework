{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zakonreal/ds_homework/blob/main/HW_DL_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "in0PyicHhZDG"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "73ieMA485Tme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8a4ee92-1dfd-474a-ac86-0a19e250a9cf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = 'drive/My Drive/'\n",
        "train_lang = 'en'"
      ],
      "metadata": {
        "id": "Os4tVkvmkTIp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class DatasetSeq(Dataset):\n",
        "    def __init__(self, data_dir, train_lang='en'):\n",
        "\t#open file\n",
        "        with open(data_dir + train_lang + '.train', 'r') as f:\n",
        "            train = f.read().split('\\n\\n')\n",
        "\n",
        "        # delete extra tag markup\n",
        "        train = [x for x in train if not '_ ' in x]\n",
        "\t    #init vocabs of tokens for encoding {<str> token: <int> id}\n",
        "        self.target_vocab = {} # {p: 1, a: 2, r: 3, pu: 4}\n",
        "        self.word_vocab = {} # {cat: 1, sat: 2, on: 3, mat: 4, '.': 5}\n",
        "        self.char_vocab = {} # {c: 1, a: 2, t: 3, ' ': 4, s: 5}\n",
        "\t    \n",
        "        # Cat sat on mat. -> [1, 2, 3, 4, 5]\n",
        "        # p    a  r  p pu -> [1, 2, 3, 1, 4]\n",
        "        # chars  -> [1, 2, 3, 4, 5, 2, 3, 4]\n",
        "\n",
        "\t    #init encoded sequences lists (processed data)\n",
        "        self.encoded_sequences = []\n",
        "        self.encoded_targets = []\n",
        "        self.encoded_char_sequences = []\n",
        "        # n=1 because first value is padding\n",
        "        n_word = 1\n",
        "        n_target = 1\n",
        "        n_char = 1\n",
        "        for line in train:\n",
        "            sequence = []\n",
        "            target = []\n",
        "            chars = []\n",
        "            for item in line.split('\\n'):\n",
        "                if item != '':\n",
        "                    word, label = item.split(' ')\n",
        "\n",
        "                    if self.word_vocab.get(word) is None:\n",
        "                        self.word_vocab[word] = n_word\n",
        "                        n_word += 1\n",
        "                    if self.target_vocab.get(label) is None:\n",
        "                        self.target_vocab[label] = n_target\n",
        "                        n_target += 1\n",
        "                    for char in word:\n",
        "                        if self.char_vocab.get(char) is None:\n",
        "                            self.char_vocab[char] = n_char\n",
        "                            n_char += 1\n",
        "                    sequence.append(self.word_vocab[word])\n",
        "                    target.append(self.target_vocab[label])\n",
        "                    chars.append([self.char_vocab[char] for char in word])\n",
        "            self.encoded_sequences.append(sequence)\n",
        "            self.encoded_targets.append(target)\n",
        "            self.encoded_char_sequences.append(chars)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encoded_sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\n",
        "            'data': self.encoded_sequences[index], # [1, 2, 3, 4, 6] len=5\n",
        "            'char': self.encoded_char_sequences[index],# [[1,2,3], [4,5], [1,2], [2,6,5,4], []] len=5\n",
        "            'target': self.encoded_targets[index], #  (1)\n",
        "        }"
      ],
      "metadata": {
        "id": "SI8UCZuy7hTK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = DatasetSeq(data_dir)"
      ],
      "metadata": {
        "id": "dhJuBtoz7f43"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding\n",
        "# seq1 = [1, 2, 3, 4]\n",
        "# seq2 = [9, 7, 6, 4, 3, 7, 5]\n",
        "# pad seq1 equal seq2\n",
        "# seq1 = [1, 2, 3, 4, 0, 0, 0]\n",
        "# concat(seq1, seq2) [[1, 2, 3, 4, 0, 0, 0],\n",
        "#                     [9, 7, 6, 4, 3, 7, 5]]"
      ],
      "metadata": {
        "id": "0zXXXYP37gFL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    data = []\n",
        "    target = []\n",
        "    for item in batch:\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        target.append(torch.as_tensor(item['target']))\n",
        "    # pad different length sequences\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    target = pad_sequence(target, batch_first=True, padding_value=0)\n",
        "\n",
        "    return {'data': data, 'target': target}"
      ],
      "metadata": {
        "id": "uPJauY4hAqJ6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNCellPredictor(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn_cell = nn.GRUCell(emb_dim, hidden_dim)\n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x): # B x T\n",
        "        b, t = x.size()\n",
        "        emb = self.word_emb(x) # B x T x Ebm_dim\n",
        "        rnn_out = []\n",
        "        hidden = torch.zeros((b, self.hidden_dim), device=x.device)\n",
        "        for i in range(t):\n",
        "            hidden = self.gru_cell(emb[:, i, :], # emb[:, i, :]: B x Emb_dim\n",
        "                                   hidden) # hidden: B x Hid_dim\n",
        "            rnn_out.append(hidden.unsqueeze(1)) # B x 1 x Hid_dim\n",
        "        rnn_out = torch.cat(rnn_out, dim=1) # B x T x Hid_dim\n",
        "\n",
        "        return self.clf(self.do(rnn_out))\n"
      ],
      "metadata": {
        "id": "KTz2txO4LTZ3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #hyper params\n",
        "# vocab_size = len(dataset.word_vocab) + 1\n",
        "# n_classes = len(dataset.target_vocab) + 1\n",
        "# n_chars = len(dataset.char_vocab) + 1\n",
        "# #TODO try to use other model parameters\n",
        "# emb_dim = 256\n",
        "# hidden = 256\n",
        "# n_epochs = 10\n",
        "# cuda_device = 0\n",
        "# batch_size = 100\n",
        "# device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "K_PACmDaH8Z7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#hyper params\n",
        "vocab_size = len(dataset.word_vocab) + 1\n",
        "n_classes = len(dataset.target_vocab) + 1\n",
        "n_chars = len(dataset.char_vocab) + 1\n",
        "#TODO try to use other model parameters\n",
        "emb_dim = 128 # поменял с 256 на 128\n",
        "hidden = 256\n",
        "char_hid = 64\n",
        "char_emb = 32\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "cuda_device = 0\n",
        "batch_size = 100\n",
        "device = f'cuda:{cuda_device}' if cuda_device != -1 else 'cpu'"
      ],
      "metadata": {
        "id": "qknU9T_TQkc5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))\n",
        "        "
      ],
      "metadata": {
        "id": "WBFZc1qY6HsC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = RNN_GRU(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model1.train()\n",
        "optim = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "a4gX5zVDIZdu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start1 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model1(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model1.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "GRU_train_time = datetime.datetime.now() - start1\n",
        "GRU_train_loss = loss.item()\n",
        "print(GRU_train_time)\n",
        "print(GRU_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2f3MATJ8GKb",
        "outputId": "68f255ce-a049-4e32-a959-39e31d377d54"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 3.080223560333252\n",
            "epoch: 0, step: 100, loss: 0.3486131727695465\n",
            "epoch: 0, step: 200, loss: 0.27183297276496887\n",
            "epoch: 1, step: 0, loss: 0.2454240620136261\n",
            "epoch: 1, step: 100, loss: 0.1549500674009323\n",
            "epoch: 1, step: 200, loss: 0.20760221779346466\n",
            "epoch: 2, step: 0, loss: 0.12521789968013763\n",
            "epoch: 2, step: 100, loss: 0.16640493273735046\n",
            "epoch: 2, step: 200, loss: 0.12093928456306458\n",
            "epoch: 3, step: 0, loss: 0.15461379289627075\n",
            "epoch: 3, step: 100, loss: 0.12022522836923599\n",
            "epoch: 3, step: 200, loss: 0.1174144297838211\n",
            "epoch: 4, step: 0, loss: 0.12748974561691284\n",
            "epoch: 4, step: 100, loss: 0.10212807357311249\n",
            "epoch: 4, step: 200, loss: 0.06491125375032425\n",
            "epoch: 5, step: 0, loss: 0.09487593173980713\n",
            "epoch: 5, step: 100, loss: 0.060610298067331314\n",
            "epoch: 5, step: 200, loss: 0.07648179680109024\n",
            "epoch: 6, step: 0, loss: 0.04808083176612854\n",
            "epoch: 6, step: 100, loss: 0.06961005181074142\n",
            "epoch: 6, step: 200, loss: 0.0790475383400917\n",
            "epoch: 7, step: 0, loss: 0.050908397883176804\n",
            "epoch: 7, step: 100, loss: 0.061339691281318665\n",
            "epoch: 7, step: 200, loss: 0.0690920501947403\n",
            "epoch: 8, step: 0, loss: 0.03970549255609512\n",
            "epoch: 8, step: 100, loss: 0.04714610427618027\n",
            "epoch: 8, step: 200, loss: 0.05609637498855591\n",
            "epoch: 9, step: 0, loss: 0.052764616906642914\n",
            "epoch: 9, step: 100, loss: 0.03366660699248314\n",
            "epoch: 9, step: 200, loss: 0.047493528574705124\n",
            "0:00:23.703363\n",
            "0.05079801753163338\n",
            "CPU times: user 21.9 s, sys: 438 ms, total: 22.4 s\n",
            "Wall time: 23.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start11 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model1.eval()\n",
        "    predict = model1(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    GRU_inference_time = datetime.datetime.now() - start11\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(GRU_inference_time)"
      ],
      "metadata": {
        "id": "9CljFAzIMMEW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "735c569b-d632-4674-afd0-a2b837300f2b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.013239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "soes4kIU8FDq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = RNN_LSTM(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model2.train()\n",
        "optim = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "9PbgCjN48FRe"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start2 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model2(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model2.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "LSTM_train_time = datetime.datetime.now() - start2\n",
        "LSTM_train_loss = loss.item()\n",
        "print(LSTM_train_time)\n",
        "print(LSTM_train_loss)"
      ],
      "metadata": {
        "id": "74gggSX58Fe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb6d61d-7c67-49a3-b455-4817ed491797"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.953162670135498\n",
            "epoch: 0, step: 100, loss: 0.2958807349205017\n",
            "epoch: 0, step: 200, loss: 0.2459028959274292\n",
            "epoch: 1, step: 0, loss: 0.2459316849708557\n",
            "epoch: 1, step: 100, loss: 0.2505510747432709\n",
            "epoch: 1, step: 200, loss: 0.11047572642564774\n",
            "epoch: 2, step: 0, loss: 0.1543336659669876\n",
            "epoch: 2, step: 100, loss: 0.1551549732685089\n",
            "epoch: 2, step: 200, loss: 0.13508357107639313\n",
            "epoch: 3, step: 0, loss: 0.12240509688854218\n",
            "epoch: 3, step: 100, loss: 0.08197642117738724\n",
            "epoch: 3, step: 200, loss: 0.08835366368293762\n",
            "epoch: 4, step: 0, loss: 0.10079345852136612\n",
            "epoch: 4, step: 100, loss: 0.1129704937338829\n",
            "epoch: 4, step: 200, loss: 0.09497163444757462\n",
            "epoch: 5, step: 0, loss: 0.06897866725921631\n",
            "epoch: 5, step: 100, loss: 0.09662687033414841\n",
            "epoch: 5, step: 200, loss: 0.0806700736284256\n",
            "epoch: 6, step: 0, loss: 0.04874956235289574\n",
            "epoch: 6, step: 100, loss: 0.07281622290611267\n",
            "epoch: 6, step: 200, loss: 0.08576046675443649\n",
            "epoch: 7, step: 0, loss: 0.026790810748934746\n",
            "epoch: 7, step: 100, loss: 0.0698654055595398\n",
            "epoch: 7, step: 200, loss: 0.06804098933935165\n",
            "epoch: 8, step: 0, loss: 0.05135989934206009\n",
            "epoch: 8, step: 100, loss: 0.03294948861002922\n",
            "epoch: 8, step: 200, loss: 0.04793628677725792\n",
            "epoch: 9, step: 0, loss: 0.026284227147698402\n",
            "epoch: 9, step: 100, loss: 0.05150606483221054\n",
            "epoch: 9, step: 200, loss: 0.06500983238220215\n",
            "0:00:24.675970\n",
            "0.050205741077661514\n",
            "CPU times: user 23.8 s, sys: 378 ms, total: 24.2 s\n",
            "Wall time: 24.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start22 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model2.eval()\n",
        "    predict = model2(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    LSTM_inference_time = datetime.datetime.now() - start22\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(LSTM_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JdDhNkOKXh7",
        "outputId": "3b4d17e1-f9f2-4cb3-b014-e75fdaee02ac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.002074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x)\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "mUKmT0hNKXsf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = RNN_LSTM(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model3.train()\n",
        "optim = torch.optim.Adam(model3.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "iRr7xCJ-KXvr"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "start3 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model3(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model3.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "RNN_train_time = datetime.datetime.now() - start3\n",
        "RNN_train_loss = loss.item()\n",
        "print(RNN_train_time)\n",
        "print(RNN_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGo7xQ2xKX22",
        "outputId": "521de7f6-c397-4e1e-cf66-054e793f2e9f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 3.0121350288391113\n",
            "epoch: 0, step: 100, loss: 0.3853045403957367\n",
            "epoch: 0, step: 200, loss: 0.27589738368988037\n",
            "epoch: 1, step: 0, loss: 0.21977126598358154\n",
            "epoch: 1, step: 100, loss: 0.1568412035703659\n",
            "epoch: 1, step: 200, loss: 0.19692200422286987\n",
            "epoch: 2, step: 0, loss: 0.18353889882564545\n",
            "epoch: 2, step: 100, loss: 0.17285144329071045\n",
            "epoch: 2, step: 200, loss: 0.1160384863615036\n",
            "epoch: 3, step: 0, loss: 0.1256759613752365\n",
            "epoch: 3, step: 100, loss: 0.0927983894944191\n",
            "epoch: 3, step: 200, loss: 0.11238019168376923\n",
            "epoch: 4, step: 0, loss: 0.07978789508342743\n",
            "epoch: 4, step: 100, loss: 0.09297657757997513\n",
            "epoch: 4, step: 200, loss: 0.09826873987913132\n",
            "epoch: 5, step: 0, loss: 0.06542126834392548\n",
            "epoch: 5, step: 100, loss: 0.06067018583416939\n",
            "epoch: 5, step: 200, loss: 0.0764235332608223\n",
            "epoch: 6, step: 0, loss: 0.0869976133108139\n",
            "epoch: 6, step: 100, loss: 0.047332506626844406\n",
            "epoch: 6, step: 200, loss: 0.033394765108823776\n",
            "epoch: 7, step: 0, loss: 0.08868604898452759\n",
            "epoch: 7, step: 100, loss: 0.07303439825773239\n",
            "epoch: 7, step: 200, loss: 0.05180426687002182\n",
            "epoch: 8, step: 0, loss: 0.05072568729519844\n",
            "epoch: 8, step: 100, loss: 0.0538773238658905\n",
            "epoch: 8, step: 200, loss: 0.06384962797164917\n",
            "epoch: 9, step: 0, loss: 0.03508898615837097\n",
            "epoch: 9, step: 100, loss: 0.03736383467912674\n",
            "epoch: 9, step: 200, loss: 0.05565764755010605\n",
            "0:00:24.574385\n",
            "0.046103447675704956\n",
            "CPU times: user 23.8 s, sys: 341 ms, total: 24.1 s\n",
            "Wall time: 24.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start33 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model3.eval()\n",
        "    predict = model3(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    RNN_inference_time = datetime.datetime.now() - start33\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(RNN_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6WK7jdJKX6p",
        "outputId": "e2640935-eda7-400c-b8df-d572bd91c327"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.001282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn1(input_data):\n",
        "    data = []\n",
        "    chars = []\n",
        "    targets = []\n",
        "    max_len = 0\n",
        "    for item in input_data:\n",
        "        if len(item['data']) > max_len:\n",
        "            max_len = len(item['data'])\n",
        "        data.append(torch.as_tensor(item['data']))\n",
        "        chars.append(item['char'])\n",
        "        targets.append(torch.as_tensor(item['target']))\n",
        "    chars_seq = [[torch.as_tensor([0]) for _ in range(len(input_data))] for _ in range(max_len)]\n",
        "    for j in range(len(input_data)):\n",
        "        for i in range(max_len):\n",
        "            if len(chars[j]) > i:\n",
        "                chars_seq[i][j] = torch.as_tensor(chars[j][i])\n",
        "    for j in range(max_len):\n",
        "        chars_seq[j] = pad_sequence(chars_seq[j], batch_first=True, padding_value=0)\n",
        "    data = pad_sequence(data, batch_first=True, padding_value=0)\n",
        "    targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
        "    return {'data': data, 'chars': chars_seq, 'target': targets}"
      ],
      "metadata": {
        "id": "vHNpwzseQPRB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN_GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.char_emb(x) # B x T x Emb_dim\n",
        "        _, out = self.rnn(emb)\n",
        "        # _: B x T x Hidden \n",
        "        # out: 1 x B x Hidden\n",
        "\n",
        "        return out.transpose(0, 1) # B x 1 x Hidden"
      ],
      "metadata": {
        "id": "LKcpp1-eQPXf"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_GRU_CH(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n",
        "                 char_vocab, char_emb, char_hidden):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.GRU(emb_dim + char_hidden, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_rnn = CharRNN_GRU(char_vocab, char_emb, char_hidden)\n",
        "\n",
        "    def forward(self, x, chars):\n",
        "        emb = self.word_emb(x)\n",
        "        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n",
        "        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n",
        "        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "8EmOuYOWQPas"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model4 = RNN_GRU_CH(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n",
        "model4.train()\n",
        "optim = torch.optim.Adam(model4.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "mJ64bvufQPeG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start4 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn1,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model4(batch['data'].to(device), batch['chars'])\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model4.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "GRUch_train_time = datetime.datetime.now() - start4\n",
        "GRUch_train_loss = loss.item()\n",
        "print(GRUch_train_time)\n",
        "print(GRUch_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwEopDefQPhX",
        "outputId": "46277ba3-509d-4071-fc00-aad840ee4127"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 3.0374703407287598\n",
            "epoch: 0, step: 100, loss: 0.36379021406173706\n",
            "epoch: 0, step: 200, loss: 0.14729586243629456\n",
            "epoch: 1, step: 0, loss: 0.23315732181072235\n",
            "epoch: 1, step: 100, loss: 0.10437831282615662\n",
            "epoch: 1, step: 200, loss: 0.12685254216194153\n",
            "epoch: 2, step: 0, loss: 0.09111455827951431\n",
            "epoch: 2, step: 100, loss: 0.09418246150016785\n",
            "epoch: 2, step: 200, loss: 0.07498889416456223\n",
            "epoch: 3, step: 0, loss: 0.11670227348804474\n",
            "epoch: 3, step: 100, loss: 0.09714780747890472\n",
            "epoch: 3, step: 200, loss: 0.072321318089962\n",
            "epoch: 4, step: 0, loss: 0.07048870623111725\n",
            "epoch: 4, step: 100, loss: 0.07767422497272491\n",
            "epoch: 4, step: 200, loss: 0.061972834169864655\n",
            "epoch: 5, step: 0, loss: 0.06485084444284439\n",
            "epoch: 5, step: 100, loss: 0.05626639351248741\n",
            "epoch: 5, step: 200, loss: 0.060968827456235886\n",
            "epoch: 6, step: 0, loss: 0.04947524517774582\n",
            "epoch: 6, step: 100, loss: 0.049071624875068665\n",
            "epoch: 6, step: 200, loss: 0.04698457568883896\n",
            "epoch: 7, step: 0, loss: 0.03712794929742813\n",
            "epoch: 7, step: 100, loss: 0.03481217846274376\n",
            "epoch: 7, step: 200, loss: 0.047730907797813416\n",
            "epoch: 8, step: 0, loss: 0.041595134884119034\n",
            "epoch: 8, step: 100, loss: 0.040724292397499084\n",
            "epoch: 8, step: 200, loss: 0.0346689373254776\n",
            "epoch: 9, step: 0, loss: 0.03546017035841942\n",
            "epoch: 9, step: 100, loss: 0.036855049431324005\n",
            "epoch: 9, step: 200, loss: 0.031592193990945816\n",
            "0:04:35.486453\n",
            "0.024747561663389206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "#TODO modify inference for model with char input\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n",
        "\n",
        "start44 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model4.eval()\n",
        "    predict = model4(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    GRUch_inference_time = datetime.datetime.now() - start44\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(GRUch_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRpQFLHpQPkc",
        "outputId": "c83d307e-e7cf-4cb1-c8ab-9cc83abc237b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.006047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN_LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.char_emb(x) # B x T x Emb_dim\n",
        "        _, (out, _) = self.rnn(emb)\n",
        "        # _: B x T x Hidden \n",
        "        # out: 1 x B x Hidden\n",
        "\n",
        "        return out.transpose(0, 1) # B x 1 x Hidden"
      ],
      "metadata": {
        "id": "DTfltWKVDnAr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_LSTM_CH(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n",
        "                 char_vocab, char_emb, char_hidden):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.LSTM(emb_dim + char_hidden, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_rnn = CharRNN_LSTM(char_vocab, char_emb, char_hidden)\n",
        "\n",
        "    def forward(self, x, chars):\n",
        "        emb = self.word_emb(x)\n",
        "        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n",
        "        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n",
        "        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "UlvXC1RoQRKH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model5 = RNN_LSTM_CH(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n",
        "model5.train()\n",
        "optim = torch.optim.Adam(model5.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Oa7azPFWQRNi"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start5 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn1,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model5(batch['data'].to(device), batch['chars'])\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model5.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "LSTMch_train_time = datetime.datetime.now() - start5\n",
        "LSTMch_train_loss = loss.item()\n",
        "print(LSTMch_train_time)\n",
        "print(LSTMch_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRWIHLEhQRRQ",
        "outputId": "e5dcc112-2fa7-4054-ea0c-dffdf73a4c64"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.922806739807129\n",
            "epoch: 0, step: 100, loss: 0.3720332086086273\n",
            "epoch: 0, step: 200, loss: 0.1747216135263443\n",
            "epoch: 1, step: 0, loss: 0.22429560124874115\n",
            "epoch: 1, step: 100, loss: 0.18093912303447723\n",
            "epoch: 1, step: 200, loss: 0.14818258583545685\n",
            "epoch: 2, step: 0, loss: 0.16499438881874084\n",
            "epoch: 2, step: 100, loss: 0.08606958389282227\n",
            "epoch: 2, step: 200, loss: 0.0834396705031395\n",
            "epoch: 3, step: 0, loss: 0.09470351040363312\n",
            "epoch: 3, step: 100, loss: 0.06257470697164536\n",
            "epoch: 3, step: 200, loss: 0.09022928029298782\n",
            "epoch: 4, step: 0, loss: 0.07597386837005615\n",
            "epoch: 4, step: 100, loss: 0.06765821576118469\n",
            "epoch: 4, step: 200, loss: 0.07093150913715363\n",
            "epoch: 5, step: 0, loss: 0.07372043281793594\n",
            "epoch: 5, step: 100, loss: 0.05874081701040268\n",
            "epoch: 5, step: 200, loss: 0.08245965838432312\n",
            "epoch: 6, step: 0, loss: 0.05250940099358559\n",
            "epoch: 6, step: 100, loss: 0.06494863331317902\n",
            "epoch: 6, step: 200, loss: 0.06947361677885056\n",
            "epoch: 7, step: 0, loss: 0.05452423542737961\n",
            "epoch: 7, step: 100, loss: 0.039993248879909515\n",
            "epoch: 7, step: 200, loss: 0.04193265363574028\n",
            "epoch: 8, step: 0, loss: 0.03617384284734726\n",
            "epoch: 8, step: 100, loss: 0.05010158196091652\n",
            "epoch: 8, step: 200, loss: 0.029834456741809845\n",
            "epoch: 9, step: 0, loss: 0.05281250178813934\n",
            "epoch: 9, step: 100, loss: 0.034581903368234634\n",
            "epoch: 9, step: 200, loss: 0.04092615470290184\n",
            "0:04:42.086672\n",
            "0.05807143822312355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "#TODO modify inference for model with char input\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n",
        "\n",
        "start55 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model5.eval()\n",
        "    predict = model5(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    LSTMch_inference_time = datetime.datetime.now() - start55\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(LSTMch_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqoQ0HA7QRU1",
        "outputId": "b1f8aeb3-0eef-4fbc-b2f1-a2b107063a33"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.007471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.char_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.char_emb(x) # B x T x Emb_dim\n",
        "        _, (out, _) = self.rnn(emb)\n",
        "        # _: B x T x Hidden \n",
        "        # out: 1 x B x Hidden\n",
        "\n",
        "        return out.transpose(0, 1) # B x 1 x Hidden"
      ],
      "metadata": {
        "id": "LUGKvb0iHj2k"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN_CH(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes,\n",
        "                 char_vocab, char_emb, char_hidden):\n",
        "        super().__init__()\n",
        "        #TODO try to use other RNN archicetures, f.e. RNN and LSTM\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # batch_first = False: T x B x Vec\n",
        "        # batch_first = True: B x T x Vec\n",
        "        self.rnn = nn.RNN(emb_dim + char_hidden, hidden_dim, batch_first=True) \n",
        "        self.clf = nn.Linear(hidden_dim, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.char_rnn = CharRNN(char_vocab, char_emb, char_hidden)\n",
        "\n",
        "    def forward(self, x, chars):\n",
        "        emb = self.word_emb(x)\n",
        "        char_features = [self.char_rnn(c.to(x.device)) for c in chars]\n",
        "        char_features = torch.cat(char_features, dim=1) # конкатенация по времени B x T x Char_hid\n",
        "        emb = torch.cat((emb, char_features), dim=-1) # конкатенация векторов\n",
        "        hidden, _ = self.rnn(emb)\n",
        "\n",
        "        return self.clf(self.do(hidden))"
      ],
      "metadata": {
        "id": "2Eb8tW4CUzVQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model6 = RNN_LSTM_CH(vocab_size, emb_dim, hidden, n_classes, n_chars, char_emb, char_hid).to(device)\n",
        "model6.train()\n",
        "optim = torch.optim.Adam(model6.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "1SYnM_F6Uzby"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start6 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn1,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model6(batch['data'].to(device), batch['chars'])\n",
        "        loss = loss_func(predict.view(-1, n_classes),\n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "   \n",
        "    torch.save(model6.state_dict(), f'./rnn_chkpt_{epoch}.pth')\n",
        "RNNch_train_time = datetime.datetime.now() - start6\n",
        "RNNch_train_loss = loss.item()\n",
        "print(RNNch_train_time)\n",
        "print(RNNch_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVyFk-UbUzhH",
        "outputId": "d8cd34b0-9ae1-4c91-d469-639bccfc3a1e"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.6681737899780273\n",
            "epoch: 0, step: 100, loss: 0.2783052623271942\n",
            "epoch: 0, step: 200, loss: 0.15804603695869446\n",
            "epoch: 1, step: 0, loss: 0.14774030447006226\n",
            "epoch: 1, step: 100, loss: 0.19393180310726166\n",
            "epoch: 1, step: 200, loss: 0.14544349908828735\n",
            "epoch: 2, step: 0, loss: 0.07463293522596359\n",
            "epoch: 2, step: 100, loss: 0.12899021804332733\n",
            "epoch: 2, step: 200, loss: 0.08633100241422653\n",
            "epoch: 3, step: 0, loss: 0.1144949421286583\n",
            "epoch: 3, step: 100, loss: 0.09094712883234024\n",
            "epoch: 3, step: 200, loss: 0.06707315891981125\n",
            "epoch: 4, step: 0, loss: 0.08500108122825623\n",
            "epoch: 4, step: 100, loss: 0.06733015179634094\n",
            "epoch: 4, step: 200, loss: 0.0754786804318428\n",
            "epoch: 5, step: 0, loss: 0.04523622617125511\n",
            "epoch: 5, step: 100, loss: 0.04777074605226517\n",
            "epoch: 5, step: 200, loss: 0.034155361354351044\n",
            "epoch: 6, step: 0, loss: 0.04652193933725357\n",
            "epoch: 6, step: 100, loss: 0.04352507367730141\n",
            "epoch: 6, step: 200, loss: 0.03464328870177269\n",
            "epoch: 7, step: 0, loss: 0.06804580241441727\n",
            "epoch: 7, step: 100, loss: 0.033799439668655396\n",
            "epoch: 7, step: 200, loss: 0.05546431615948677\n",
            "epoch: 8, step: 0, loss: 0.044821757823228836\n",
            "epoch: 8, step: 100, loss: 0.06304200738668442\n",
            "epoch: 8, step: 200, loss: 0.04342430830001831\n",
            "epoch: 9, step: 0, loss: 0.04196346178650856\n",
            "epoch: 9, step: 100, loss: 0.0439213290810585\n",
            "epoch: 9, step: 200, loss: 0.0414343886077404\n",
            "0:04:37.866263\n",
            "0.048879656940698624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example\n",
        "#TODO modify inference for model with char input\n",
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "chars = [torch.tensor([dataset.char_vocab[c] for c in w]).unsqueeze(0).to(device) for w in words]\n",
        "\n",
        "start66 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model5.eval()\n",
        "    predict = model5(torch.tensor(tokens).unsqueeze(0).to(device), chars) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    RNNch_inference_time = datetime.datetime.now() - start66\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l-1] for l in labels])\n",
        "print(RNNch_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtTTCB1bUzlX",
        "outputId": "e390b393-2880-4381-8f69-07f9a146b4f8"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PRON', 'VERB', 'ADV', 'SCONJ', 'DET', 'ADJ', 'NOUN', 'CCONJ', 'VERB', 'PRON']\n",
            "0:00:00.005693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirGRU(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.clf = nn.Linear(hidden_dim * 2, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x) # B x T x Emb_dim\n",
        "        hidden, _ = self.rnn(emb)   # B x T x Hid, B x 1 x Hid\n",
        "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "gQ9BYO2Oziy9"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model7 = BidirGRU(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model7.train()\n",
        "optim = torch.optim.Adam(model7.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5z7R773587ac"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start7 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model7(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),           \n",
        "                         batch['target'].to(device).view(-1),   \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "BidirGRU_train_time = datetime.datetime.now() - start7\n",
        "BidirGRU_train_loss = loss.item()\n",
        "print(BidirGRU_train_time)\n",
        "print(BidirGRU_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojeli73x87dk",
        "outputId": "6c325c55-b798-4d7c-8a07-fabcd33851a6"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.906492233276367\n",
            "epoch: 0, step: 100, loss: 0.22063975036144257\n",
            "epoch: 0, step: 200, loss: 0.2156628668308258\n",
            "epoch: 1, step: 0, loss: 0.15258242189884186\n",
            "epoch: 1, step: 100, loss: 0.11334028840065002\n",
            "epoch: 1, step: 200, loss: 0.09139696508646011\n",
            "epoch: 2, step: 0, loss: 0.1473435014486313\n",
            "epoch: 2, step: 100, loss: 0.12349286675453186\n",
            "epoch: 2, step: 200, loss: 0.10069135576486588\n",
            "epoch: 3, step: 0, loss: 0.0828949511051178\n",
            "epoch: 3, step: 100, loss: 0.06977857649326324\n",
            "epoch: 3, step: 200, loss: 0.0662541538476944\n",
            "epoch: 4, step: 0, loss: 0.06941991299390793\n",
            "epoch: 4, step: 100, loss: 0.06935705244541168\n",
            "epoch: 4, step: 200, loss: 0.06514900922775269\n",
            "epoch: 5, step: 0, loss: 0.04567907750606537\n",
            "epoch: 5, step: 100, loss: 0.06725462526082993\n",
            "epoch: 5, step: 200, loss: 0.0535103976726532\n",
            "epoch: 6, step: 0, loss: 0.038662999868392944\n",
            "epoch: 6, step: 100, loss: 0.044430047273635864\n",
            "epoch: 6, step: 200, loss: 0.03158709034323692\n",
            "epoch: 7, step: 0, loss: 0.030812283977866173\n",
            "epoch: 7, step: 100, loss: 0.024538356810808182\n",
            "epoch: 7, step: 200, loss: 0.02905268222093582\n",
            "epoch: 8, step: 0, loss: 0.022030405700206757\n",
            "epoch: 8, step: 100, loss: 0.022431310266256332\n",
            "epoch: 8, step: 200, loss: 0.031528618186712265\n",
            "epoch: 9, step: 0, loss: 0.014603808522224426\n",
            "epoch: 9, step: 100, loss: 0.023017585277557373\n",
            "epoch: 9, step: 200, loss: 0.012668007984757423\n",
            "0:00:34.523410\n",
            "0.02373432368040085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start77 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model7.eval()\n",
        "    predict = model7(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    BidirGRU_inference_time = datetime.datetime.now() - start77\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])\n",
        "print(BidirGRU_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOZpYfPe87g0",
        "outputId": "37352f27-d658-4d5b-eef0-8bf204f81861"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'AUX', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n",
            "0:00:00.001572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        # делается эмбеддинг последовательности и целиком передается в RNN\n",
        "        self.rnn = nn.LSTM(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.clf = nn.Linear(hidden_dim * 2, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x) # B x T x Emb_dim\n",
        "        hidden, _ = self.rnn(emb)   # B x T x Hid, B x 1 x Hid\n",
        "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "62hIi8eWzinF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model8 = BidirLSTM(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model8.train()\n",
        "optim = torch.optim.Adam(model8.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "sYLixwe2zip6"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start8 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model8(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),           \n",
        "                         batch['target'].to(device).view(-1), \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "BidirLSTM_train_time = datetime.datetime.now() - start8\n",
        "BidirLSTM_train_loss = loss.item()\n",
        "print(BidirLSTM_train_time)\n",
        "print(BidirLSTM_train_loss)"
      ],
      "metadata": {
        "id": "C2t6oOjlzisz",
        "outputId": "be6ad6fb-bf07-490b-d142-bec7490a9672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.8287649154663086\n",
            "epoch: 0, step: 100, loss: 0.4153827130794525\n",
            "epoch: 0, step: 200, loss: 0.19193825125694275\n",
            "epoch: 1, step: 0, loss: 0.10457520186901093\n",
            "epoch: 1, step: 100, loss: 0.11908552050590515\n",
            "epoch: 1, step: 200, loss: 0.1354791820049286\n",
            "epoch: 2, step: 0, loss: 0.0984041765332222\n",
            "epoch: 2, step: 100, loss: 0.15424974262714386\n",
            "epoch: 2, step: 200, loss: 0.12271416932344437\n",
            "epoch: 3, step: 0, loss: 0.08871078491210938\n",
            "epoch: 3, step: 100, loss: 0.07945622503757477\n",
            "epoch: 3, step: 200, loss: 0.09227223694324493\n",
            "epoch: 4, step: 0, loss: 0.054314859211444855\n",
            "epoch: 4, step: 100, loss: 0.052780892699956894\n",
            "epoch: 4, step: 200, loss: 0.05633893609046936\n",
            "epoch: 5, step: 0, loss: 0.04962976649403572\n",
            "epoch: 5, step: 100, loss: 0.061578765511512756\n",
            "epoch: 5, step: 200, loss: 0.03836958110332489\n",
            "epoch: 6, step: 0, loss: 0.037247184664011\n",
            "epoch: 6, step: 100, loss: 0.04315862059593201\n",
            "epoch: 6, step: 200, loss: 0.020625604316592216\n",
            "epoch: 7, step: 0, loss: 0.03518318757414818\n",
            "epoch: 7, step: 100, loss: 0.03580974414944649\n",
            "epoch: 7, step: 200, loss: 0.034591179341077805\n",
            "epoch: 8, step: 0, loss: 0.03228098899126053\n",
            "epoch: 8, step: 100, loss: 0.022703375667333603\n",
            "epoch: 8, step: 200, loss: 0.02626025676727295\n",
            "epoch: 9, step: 0, loss: 0.017358317971229553\n",
            "epoch: 9, step: 100, loss: 0.020134853199124336\n",
            "epoch: 9, step: 200, loss: 0.014326803386211395\n",
            "0:00:40.553661\n",
            "0.03505577892065048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start88 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model8.eval()\n",
        "    predict = model8(torch.tensor(tokens).unsqueeze(0).to(device))\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    BidirLSTM_inference_time = datetime.datetime.now() - start88\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])\n",
        "print(BidirLSTM_inference_time)"
      ],
      "metadata": {
        "id": "KDXQe3lpzivy",
        "outputId": "342174ca-c85d-42d7-86e0-c6e90c1bf0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'AUX', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n",
            "0:00:00.002357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BidirRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hidden_dim, n_classes):\n",
        "        super().__init__()\n",
        "        self.word_emb = nn.Embedding(vocab_size, emb_dim)\n",
        "        self.rnn = nn.RNN(emb_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.clf = nn.Linear(hidden_dim * 2, n_classes)\n",
        "        self.do = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.word_emb(x) # B x T x Emb_dim\n",
        "        hidden, _ = self.rnn(emb)   # B x T x Hid, B x 1 x Hid\n",
        "        pred = self.clf(self.do(hidden)) # B x T x N_classes\n",
        "\n",
        "        return pred"
      ],
      "metadata": {
        "id": "2pdQ5Hru87ju"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model9 = BidirRNN(vocab_size, emb_dim, hidden, n_classes).to(device)\n",
        "model9.train()\n",
        "optim = torch.optim.Adam(model9.parameters(), lr=0.001)\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "gi-Kxq1587mk"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start9 = datetime.datetime.now()\n",
        "for epoch in range(n_epochs):\n",
        "    dataloader = DataLoader(dataset, \n",
        "                            batch_size, \n",
        "                            shuffle=True, \n",
        "                            collate_fn=collate_fn,\n",
        "                            drop_last = True,\n",
        "                            )\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        optim.zero_grad()\n",
        "\n",
        "        predict = model9(batch['data'].to(device))\n",
        "        loss = loss_func(predict.view(-1, n_classes),          \n",
        "                         batch['target'].to(device).view(-1),   \n",
        "                         )\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        if i % 100 == 0:\n",
        "            print(f'epoch: {epoch}, step: {i}, loss: {loss.item()}')\n",
        "BidirRNN_train_time = datetime.datetime.now() - start9\n",
        "BidirRNN_train_loss = loss.item()\n",
        "print(BidirRNN_train_time)\n",
        "print(BidirRNN_train_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5x76rFx87pa",
        "outputId": "a46588e7-0326-4521-896f-a64dc008bbf2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, step: 0, loss: 2.954439878463745\n",
            "epoch: 0, step: 100, loss: 0.26842403411865234\n",
            "epoch: 0, step: 200, loss: 0.17197299003601074\n",
            "epoch: 1, step: 0, loss: 0.195296049118042\n",
            "epoch: 1, step: 100, loss: 0.16741614043712616\n",
            "epoch: 1, step: 200, loss: 0.15104952454566956\n",
            "epoch: 2, step: 0, loss: 0.08822799474000931\n",
            "epoch: 2, step: 100, loss: 0.14336693286895752\n",
            "epoch: 2, step: 200, loss: 0.14464113116264343\n",
            "epoch: 3, step: 0, loss: 0.10332568734884262\n",
            "epoch: 3, step: 100, loss: 0.06360110640525818\n",
            "epoch: 3, step: 200, loss: 0.10531620681285858\n",
            "epoch: 4, step: 0, loss: 0.07737813144922256\n",
            "epoch: 4, step: 100, loss: 0.06274492293596268\n",
            "epoch: 4, step: 200, loss: 0.07158917188644409\n",
            "epoch: 5, step: 0, loss: 0.05476449429988861\n",
            "epoch: 5, step: 100, loss: 0.06136023625731468\n",
            "epoch: 5, step: 200, loss: 0.05160776898264885\n",
            "epoch: 6, step: 0, loss: 0.03711242973804474\n",
            "epoch: 6, step: 100, loss: 0.06285872310400009\n",
            "epoch: 6, step: 200, loss: 0.0571368969976902\n",
            "epoch: 7, step: 0, loss: 0.05482959374785423\n",
            "epoch: 7, step: 100, loss: 0.055456724017858505\n",
            "epoch: 7, step: 200, loss: 0.03828075900673866\n",
            "epoch: 8, step: 0, loss: 0.03916402533650398\n",
            "epoch: 8, step: 100, loss: 0.04450249671936035\n",
            "epoch: 8, step: 200, loss: 0.04248880222439766\n",
            "epoch: 9, step: 0, loss: 0.022733042016625404\n",
            "epoch: 9, step: 100, loss: 0.04378671199083328\n",
            "epoch: 9, step: 200, loss: 0.03512626886367798\n",
            "0:00:24.457324\n",
            "0.04026225209236145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "phrase = 'He ran quickly after the red bus and caught it'\n",
        "words = phrase.split(' ')\n",
        "tokens = [dataset.word_vocab[w] for w in words]\n",
        "\n",
        "start99 = datetime.datetime.now()\n",
        "with torch.no_grad():\n",
        "    model9.eval()\n",
        "    predict = model9(torch.tensor(tokens).unsqueeze(0).to(device)) # 1 x T x N_classes\n",
        "    labels = torch.argmax(predict, dim=-1).squeeze().cpu().detach().tolist()\n",
        "    BidirRNN_inference_time = datetime.datetime.now() - start99\n",
        "\n",
        "target_labels = list(dataset.target_vocab.keys())\n",
        "print([target_labels[l] for l in labels])\n",
        "print(BidirRNN_inference_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VR9UZht887rd",
        "outputId": "da00fa6e-41fa-4a2f-9b1f-2e4036b8cd94"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['PART', 'DET', 'CCONJ', 'AUX', 'ADP', 'NOUN', 'VERB', 'X', 'DET', 'PART']\n",
            "0:00:00.003517\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = pd.DataFrame(data=[[GRU_train_time, GRU_train_loss, GRU_inference_time],\n",
        "                            [LSTM_train_time, LSTM_train_loss, LSTM_inference_time],\n",
        "                            [RNN_train_time, RNN_train_loss, RNN_inference_time],\n",
        "                            [GRUch_train_time, GRUch_train_loss, GRUch_inference_time],\n",
        "                            [LSTMch_train_time, LSTMch_train_loss, LSTMch_inference_time],\n",
        "                            [RNNch_train_time, RNNch_train_loss, RNNch_inference_time],\n",
        "                            [BidirGRU_train_time, BidirGRU_train_loss, BidirGRU_inference_time],\n",
        "                            [BidirLSTM_train_time, BidirLSTM_train_loss, BidirLSTM_inference_time],\n",
        "                            [BidirRNN_train_time, BidirRNN_train_loss, BidirRNN_inference_time]],\n",
        "                      index = ['GRU','LSTM','RNN', 'GRUch','LSTMch','RNNch','Bidirectional GRU','Bidirectional LSTM','Bidirectional RNN'],\n",
        "                      columns = ['Время обучения', 'Loss на обучающей выборке', 'Время инференса'])\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "D9y4lzZfL7Ai",
        "outputId": "6b1f5025-fee5-4694-e55a-d9c1a60f2ed3"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           Время обучения  Loss на обучающей выборке  \\\n",
              "GRU                0 days 00:00:23.703363                   0.050798   \n",
              "LSTM               0 days 00:00:24.675970                   0.050206   \n",
              "RNN                0 days 00:00:24.574385                   0.046103   \n",
              "GRUch              0 days 00:04:35.486453                   0.024748   \n",
              "LSTMch             0 days 00:04:42.086672                   0.058071   \n",
              "RNNch              0 days 00:04:37.866263                   0.048880   \n",
              "Bidirectional GRU  0 days 00:00:34.523410                   0.023734   \n",
              "Bidirectional LSTM 0 days 00:00:40.553661                   0.035056   \n",
              "Bidirectional RNN  0 days 00:00:24.457324                   0.040262   \n",
              "\n",
              "                          Время инференса  \n",
              "GRU                0 days 00:00:00.013239  \n",
              "LSTM               0 days 00:00:00.002074  \n",
              "RNN                0 days 00:00:00.001282  \n",
              "GRUch              0 days 00:00:00.006047  \n",
              "LSTMch             0 days 00:00:00.007471  \n",
              "RNNch              0 days 00:00:00.005693  \n",
              "Bidirectional GRU  0 days 00:00:00.001572  \n",
              "Bidirectional LSTM 0 days 00:00:00.002357  \n",
              "Bidirectional RNN  0 days 00:00:00.003517  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a81045c0-32a7-433b-b032-9d70de24c47d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Время обучения</th>\n",
              "      <th>Loss на обучающей выборке</th>\n",
              "      <th>Время инференса</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0 days 00:00:23.703363</td>\n",
              "      <td>0.050798</td>\n",
              "      <td>0 days 00:00:00.013239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>0 days 00:00:24.675970</td>\n",
              "      <td>0.050206</td>\n",
              "      <td>0 days 00:00:00.002074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNN</th>\n",
              "      <td>0 days 00:00:24.574385</td>\n",
              "      <td>0.046103</td>\n",
              "      <td>0 days 00:00:00.001282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRUch</th>\n",
              "      <td>0 days 00:04:35.486453</td>\n",
              "      <td>0.024748</td>\n",
              "      <td>0 days 00:00:00.006047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTMch</th>\n",
              "      <td>0 days 00:04:42.086672</td>\n",
              "      <td>0.058071</td>\n",
              "      <td>0 days 00:00:00.007471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RNNch</th>\n",
              "      <td>0 days 00:04:37.866263</td>\n",
              "      <td>0.048880</td>\n",
              "      <td>0 days 00:00:00.005693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bidirectional GRU</th>\n",
              "      <td>0 days 00:00:34.523410</td>\n",
              "      <td>0.023734</td>\n",
              "      <td>0 days 00:00:00.001572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bidirectional LSTM</th>\n",
              "      <td>0 days 00:00:40.553661</td>\n",
              "      <td>0.035056</td>\n",
              "      <td>0 days 00:00:00.002357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bidirectional RNN</th>\n",
              "      <td>0 days 00:00:24.457324</td>\n",
              "      <td>0.040262</td>\n",
              "      <td>0 days 00:00:00.003517</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a81045c0-32a7-433b-b032-9d70de24c47d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a81045c0-32a7-433b-b032-9d70de24c47d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a81045c0-32a7-433b-b032-9d70de24c47d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-57Jq-CW8NmD"
      }
    }
  ]
}